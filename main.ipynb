{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "UD2sEOeHwTmP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install dependencies"
      ],
      "metadata": {
        "id": "YhKz-QUs12Y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile README.md\n",
        "Overview\n",
        "\n",
        "--------\n",
        "\n",
        "This coding exercise will help us understand how you approach some of the common problems we see in data engineering. Ask questions if things are unclear, use best practices and common software patterns, and feel free to go the extra mile to show off your skills. Imagine you are handing off your completed project to someone else to maintain -- it should be clear to another developer how things work and your reasoning behind your design decisions.\n",
        "\n",
        "You will be asked to ingest some weather and crop yield data (provided), design a database schema for it, and expose the data through a REST API. You may use whatever software tools you would like to answer the problems below, but keep in mind the skills required for the position you are applying for and how best to demonstrate them. Read through all the problems before beginning, as later problems may inform your approach to earlier problems.\n",
        "\n",
        "You can retrieve the data required for this exercise by cloning this repository:\n",
        "\n",
        "https://github.com/corteva/code-challenge-template\n",
        "\n",
        "Weather Data Description\n",
        "\n",
        "------------------------\n",
        "\n",
        "The wx\\_data directory has files containing weather data records from 1985-01-01 to 2014-12-31. Each file corresponds to a particular weather station from Nebraska, Iowa, Illinois, Indiana, or Ohio.\n",
        "\n",
        "Each line in the file contains 4 records separated by tabs:\n",
        "\n",
        "1. The date (YYYYMMDD format)\n",
        "\n",
        "2. The maximum temperature for that day (in tenths of a degree Celsius)\n",
        "\n",
        "3. The minimum temperature for that day (in tenths of a degree Celsius)\n",
        "\n",
        "4. The amount of precipitation for that day (in tenths of a millimeter)\n",
        "\n",
        "Missing values are indicated by the value -9999.\n",
        "\n",
        "Problem 1 - Data Modeling\n",
        "\n",
        "-------------------------\n",
        "\n",
        "Choose a database to use for this coding exercise (SQLite, Postgres, etc.). Design a data model to represent the weather data records. If you use an ORM, your answer should be in the form of that ORM's data definition format. If you use pure SQL, your answer should be in the form of DDL statements.\n",
        "\n",
        "Problem 2 - Ingestion\n",
        "\n",
        "---------------------\n",
        "\n",
        "Write code to ingest the weather data from the raw text files supplied into your database, using the model you designed. Check for duplicates: if your code is run twice, you should not end up with multiple rows with the same data in your database. Your code should also produce log output indicating start and end times and number of records ingested.\n",
        "\n",
        "Problem 3 - Data Analysis\n",
        "\n",
        "-------------------------\n",
        "\n",
        "For every year, for every weather station, calculate:\n",
        "\n",
        "\\* Average maximum temperature (in degrees Celsius)\n",
        "\n",
        "\\* Average minimum temperature (in degrees Celsius)\n",
        "\n",
        "\\* Total accumulated precipitation (in centimeters)\n",
        "\n",
        "Ignore missing data when calculating these statistics.\n",
        "\n",
        "Design a new data model to store the results. Use NULL for statistics that cannot be calculated.\n",
        "\n",
        "Your answer should include the new model definition as well as the code used to calculate the new values and store them in the database.\n",
        "\n",
        "Problem 4 - REST API\n",
        "\n",
        "--------------------\n",
        "\n",
        "Choose a web framework (e.g. Flask, Django REST Framework). Create a REST API with the following GET endpoints:\n",
        "\n",
        "/api/weather\n",
        "\n",
        "/api/weather/stats\n",
        "\n",
        "Both endpoints should return a JSON-formatted response with a representation of the ingested/calculated data in your database. Allow clients to filter the response by date and station ID (where present) using the query string. Data should be paginated.\n",
        "\n",
        "Include a Swagger/OpenAPI endpoint that provides automatic documentation of your API.\n",
        "\n",
        "Your answer should include all files necessary to run your API locally, along with any unit tests.\n",
        "\n",
        "Extra Credit - Deployment\n",
        "\n",
        "-------------------------\n",
        "\n",
        "(Optional.) Assume you are asked to get your code running in the cloud using AWS. What tools and AWS services would you use to deploy the API, database, and a scheduled version of your data ingestion code? Write up a description of your approach.\n",
        "\n",
        "---\n",
        "\n",
        "Submitting Your Answers\n",
        "\n",
        "-----------------------\n",
        "\n",
        "Consider using a linter, code formatter, and including tests and code comments. Anything that helps us understand your thought process is helpful!\n",
        "\n",
        "Please provide us with a link to your Git repository, hosted on GitHub/GitLab, containing your answers and code."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRJK9LrJ9moO",
        "outputId": "72b894b5-d453-4b6c-eae3-8156f7c185a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "requests\n",
        "flask "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzmlDfDi14DN",
        "outputId": "dc5b59af-50c1-4f11-a3b8-79fba89bb59a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "n9zws2YA19sD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Download"
      ],
      "metadata": {
        "id": "Uak4d2uf0rIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir submission\n",
        "%cd submission\n",
        "!git clone https://github.com/corteva/code-challenge-template\n",
        "!mv code-challenge-template/wx_data data\n",
        "!rm -r code-challenge-template"
      ],
      "metadata": {
        "id": "TdJTvOvewOvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "ZWJK3C0m0qLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "xtUA7nA-0pmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameters"
      ],
      "metadata": {
        "id": "kp6npB7D3lx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the directory containing the weather data files\n",
        "DATA_DIR = \"./data\"\n",
        "\n",
        "# Path to the sqlite database\n",
        "DATABASE_PATH = 'weather.db'"
      ],
      "metadata": {
        "id": "95ZMhlYk3n1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions"
      ],
      "metadata": {
        "id": "op75u7BK5XNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_sql(conn, query):\n",
        "    \"\"\"function that executes the given sql query in provided connection database\n",
        "    Args:\n",
        "        conn (sqlite3.Connection): Connection object\n",
        "        query (str): SQL query to be executed\n",
        "    Returns:\n",
        "        None\n",
        "    Raise:\n",
        "        NA\n",
        "    \"\"\"\n",
        "    # create a cursor to the connection\n",
        "    c = conn.cursor()\n",
        "\n",
        "    # Execute the query\n",
        "    c.execute(query)\n",
        "\n",
        "    # Save (commit) the changes\n",
        "    conn.commit()"
      ],
      "metadata": {
        "id": "Jbu_TV2B5aBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Modeling"
      ],
      "metadata": {
        "id": "OaH1hitrwUog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new SQLite database and connecting to it\n",
        "conn = sqlite3.connect(DATABASE_PATH)\n",
        "\n",
        "# DDL to create the table\n",
        "query = '''\n",
        "CREATE TABLE weather_data (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    station_id INTEGER NOT NULL,\n",
        "    date INTEGER NOT NULL,\n",
        "    max_temp REAL NOT NULL,\n",
        "    min_temp REAL NOT NULL,\n",
        "    precipitation REAL NOT NULL\n",
        ")\n",
        "'''\n",
        "\n",
        "# execute the query\n",
        "execute_sql(conn, query)\n",
        "\n",
        "# We can also close the connection if we are done with it.\n",
        "# Just be sure any changes have been committed or they will be lost.\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "RMQnrgoAwTSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ingestion"
      ],
      "metadata": {
        "id": "uOP8WmFi3bKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the database\n",
        "conn = sqlite3.connect(DATABASE_PATH)\n",
        "\n",
        "# start time of the data ingestion process\n",
        "start_time = time.time()\n",
        "\n",
        "# Iterate through the data files and insert data into the database\n",
        "for filename in os.listdir(DATA_DIR):\n",
        "    if filename.startswith(\"USC\"):\n",
        "        station_id = filename[3:6]\n",
        "        with open(os.path.join(DATA_DIR, filename), \"r\") as f:\n",
        "            for line in f:\n",
        "                date, max_temp, min_temp, precipitation = line.strip().split(\"\\t\")\n",
        "                # Skip lines with missing data\n",
        "                if max_temp == \"-9999\" or min_temp == \"-9999\" or precipitation == \"-9999\":\n",
        "                    continue\n",
        "                insert_sql = \"\"\"\n",
        "                INSERT OR IGNORE INTO weather_data\n",
        "                (station_id, date, max_temp, min_temp, precipitation)\n",
        "                VALUES (?, ?, ?, ?, ?)\n",
        "                \"\"\"\n",
        "                conn.execute(insert_sql, (int(station_id), int(date), int(max_temp)/10, int(min_temp)/10, int(precipitation)/10))\n",
        "conn.commit()\n",
        "\n",
        "# Print the number of records ingested\n",
        "select_count_sql = \"SELECT COUNT(*) FROM weather_data\"\n",
        "print(f\"Number of records ingested: {conn.execute(select_count_sql).fetchone()[0]}\")\n",
        "\n",
        "# Close the connection\n",
        "conn.close()\n",
        "end_time = time.time()\n",
        "print(f'Records were ingested in {end_time - start_time:.2f} seconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV0JSrDpzY84",
        "outputId": "751a151b-848b-4f3c-db2c-c327b8e118f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records ingested: 1669107\n",
            "Records were ingested in 10.23 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Analysis"
      ],
      "metadata": {
        "id": "GnTUFUAp419J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new SQLite database and connecting to it\n",
        "conn = sqlite3.connect(DATABASE_PATH)\n",
        "\n",
        "# sql query for data analysis\n",
        "query_create_table = '''\n",
        "CREATE TABLE weather_data_analysis (\n",
        "    year INTEGER NOT NULL,\n",
        "    station_id INTEGER NOT NULL,\n",
        "    avg_max_temp REAL,\n",
        "    avg_min_temp REAL,\n",
        "    total_precipitation REAL,\n",
        "    PRIMARY KEY (year, station_id)\n",
        ");\n",
        "'''\n",
        "\n",
        "query_insert = '''\n",
        "INSERT INTO weather_data_analysis\n",
        "SELECT\n",
        "    substr(date, 1, 4) AS year,\n",
        "    station_id,\n",
        "    AVG(CASE WHEN max_temp != -9999 THEN max_temp/10.0 ELSE NULL END) AS avg_max_temp,\n",
        "    AVG(CASE WHEN min_temp != -9999 THEN min_temp/10.0 ELSE NULL END) AS avg_min_temp,\n",
        "    SUM(CASE WHEN precipitation != -9999 THEN precipitation/10.0 ELSE NULL END) AS total_precipitation\n",
        "FROM weather_data\n",
        "GROUP BY year, station_id;\n",
        "'''\n",
        "\n",
        "# Execute the queries\n",
        "execute_sql(conn, query_create_table)\n",
        "execute_sql(conn, query_insert)\n",
        "\n",
        "# Close the connection\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "4h541TBR2Ypf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## REST API"
      ],
      "metadata": {
        "id": "nfuBIJJi7BV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from flask import Flask, request, jsonify\n",
        "import sqlite3\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/api')\n",
        "def hello_world():\n",
        "    return 'API for weather data!'\n",
        "\n",
        "\n",
        "conn = sqlite3.connect('weather.db', check_same_thread=False)\n",
        "\n",
        "\n",
        "@app.route('/api/weather', methods=['GET'])\n",
        "def get_weather():\n",
        "\n",
        "    # get query parameters\n",
        "    station_id = request.args.get('station_id')\n",
        "    date = request.args.get('date')\n",
        "\n",
        "    # get page parameters\n",
        "    page = request.args.get('page', default=1, type=int)\n",
        "    per_page = 10\n",
        "    offset = (page - 1) * per_page\n",
        "    \n",
        "    # build the query\n",
        "    query = 'SELECT * FROM weather_data'\n",
        "    if station_id:\n",
        "        query += f' WHERE station_id = {station_id}'\n",
        "    if date:\n",
        "        query += f' WHERE date = {date}'\n",
        "    else:\n",
        "        query += f' LIMIT {per_page} OFFSET {offset} '\n",
        "\n",
        "    # execute the query\n",
        "    cursor = conn.execute(query)\n",
        "    rows = cursor.fetchall()\n",
        "    results = []\n",
        "    \n",
        "    for row in rows:\n",
        "        results.append({\n",
        "            'date': row[2],\n",
        "            'station_id': row[1],\n",
        "            'max_temp': row[3],\n",
        "            'min_temp': row[4],\n",
        "            'precipitation': row[5]\n",
        "        })\n",
        "\n",
        "    return jsonify(results)\n",
        "\n",
        "\n",
        "@app.route('/api/weather/stats', methods=['GET'])\n",
        "def get_weather_stats():\n",
        "\n",
        "    # get page parameters\n",
        "    page = request.args.get('page', default=1, type=int)\n",
        "    per_page = 10\n",
        "    offset = (page - 1) * per_page\n",
        "\n",
        "    # get query parameters\n",
        "    station_id = request.args.get('station_id')\n",
        "\n",
        "    # build the query\n",
        "    query = 'SELECT * FROM weather_data_analysis'\n",
        "    if station_id:\n",
        "        query += f' WHERE station_id = {station_id}'\n",
        "    else:\n",
        "        query += f' LIMIT {per_page} OFFSET {offset} '\n",
        "\n",
        "    # execute the query\n",
        "    cursor = conn.execute(query)\n",
        "    rows = cursor.fetchall()\n",
        "    results = []\n",
        "\n",
        "    for row in rows:\n",
        "        results.append({\n",
        "            'year': row[0],\n",
        "            'station_id': row[1],\n",
        "            'avg_max_temp': row[2],\n",
        "            'avg_min_temp': row[3],\n",
        "            'total_precipitation': row[4]\n",
        "        })\n",
        "    \n",
        "    return jsonify(results)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "id": "7l46MhGm5UD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_app.py\n",
        "import pytest\n",
        "from app import app\n",
        "\n",
        "def test_get_weather():\n",
        "    with app.test_client() as client:\n",
        "        response = client.get('/api')\n",
        "        assert response.status_code == 200"
      ],
      "metadata": {
        "id": "Kjk78gXj7xp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_unit.py\n",
        "import unittest\n",
        "import requests\n",
        "import json\n",
        "\n",
        "class TestWeatherAPI(unittest.TestCase):\n",
        "\n",
        "    def setUp(self):\n",
        "        self.base_url = 'http://127.0.0.1:5000/api/weather'\n",
        "\n",
        "\n",
        "    def test_get_weather_by_date(self):\n",
        "        # Test getting weather data by date\n",
        "        response = requests.get(self.base_url + '?date=19850102')\n",
        "        self.assertEqual(response.status_code, 200)\n",
        "        results = json.loads(response.text)\n",
        "        self.assertGreater(len(results), 0)\n",
        "        for result in results:\n",
        "            self.assertEqual(result['date'], '19850102')\n",
        "        \n",
        "        \n",
        "\n",
        "    def test_get_weather_by_station_ID(self):\n",
        "        # Test getting weather data by station ID\n",
        "        response = requests.get(self.base_url + '?station_id=1')\n",
        "        self.assertEqual(response.status_code, 200)\n",
        "        results = json.loads(response.text)\n",
        "        self.assertGreater(len(results), 0)\n",
        "        for result in results:\n",
        "            self.assertEqual(result['station_id'], 1)\n",
        "\n",
        "\n",
        "    def test_get_weather_stats_by_station_ID(self):\n",
        "        # Test getting weather data by station ID\n",
        "        response = requests.get(self.base_url + '/stats?station_id=1')\n",
        "        self.assertEqual(response.status_code, 200)\n",
        "        results = json.loads(response.text)\n",
        "        self.assertGreater(len(results), 0)\n",
        "        for result in results:\n",
        "            self.assertEqual(result['station_id'], 1)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main()"
      ],
      "metadata": {
        "id": "nRYDMtRW74-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile swagger.yaml\n",
        "openapi: 3.0.0\n",
        "\n",
        "info:\n",
        "  title: Weather data analysis API\n",
        "  author: Data Engineering Candidate\n",
        "  version: 1.0.0\n",
        "  description: This API provides access to weather data for a given date or station ID. It Also provides statistical data of weather for given statio ID\n",
        "\n",
        "servers:\n",
        "  - url: http://127.0.0.1:5000/\n",
        "\n",
        "paths:\n",
        "  \n",
        "  api:\n",
        "    get:\n",
        "      summary: Server Port check\n",
        "      descreption: Returns \"API for weather data\" as text \n",
        "      responses:\n",
        "        '200':\n",
        "          descreption: Successful operation\n",
        "          content: \"API for weather data\"\n",
        "        '400':\n",
        "          description: Invalid request\n",
        "\n",
        "\n",
        "  api/weather:\n",
        "    get:\n",
        "      summary: Retrieve weather data\n",
        "      description: Returns weather data filtered by date and station ID\n",
        "      parameters:\n",
        "        - in: query\n",
        "          name: date\n",
        "          schema:\n",
        "            type: integer\n",
        "            format: date\n",
        "          description: Date of the weather data to retrieve (YYYYMMDD)\n",
        "        - in: query\n",
        "          name: station_id\n",
        "          schema:\n",
        "            type: integer\n",
        "          description: ID of the weather station\n",
        "        - in: query\n",
        "          name: page\n",
        "          schema:\n",
        "            type: integer\n",
        "            default: 1\n",
        "          description: Page number for pagination\n",
        "        - in: query\n",
        "          name: \n",
        "          schema:\n",
        "            type: \n",
        "            default: \n",
        "          description: Returns all results with default pagenumber applicable\n",
        "      responses:\n",
        "        '200':\n",
        "          description: Successful operation\n",
        "          content:\n",
        "            application/json:\n",
        "              schema:\n",
        "                type: array\n",
        "                items:\n",
        "                  type: object\n",
        "                  properties:\n",
        "                    date:\n",
        "                      type: integer\n",
        "                      description: Date of the weather data\n",
        "                    station_id:\n",
        "                      type: integer\n",
        "                      description: ID of the weather station\n",
        "                    maximum_temperature:\n",
        "                      type: number\n",
        "                      format: real\n",
        "                      description: Maximum temperature (in degrees Celsius)\n",
        "                    minimum_temperature:\n",
        "                      type: number\n",
        "                      format: real\n",
        "                      description: Minimum temperature (in degrees Celsius)\n",
        "                    precipitation:\n",
        "                      type: number\n",
        "                      format: real\n",
        "                      description: Precipitation (in centimeters)\n",
        "        '400':\n",
        "          description: Invalid request\n",
        "  \n",
        "  \n",
        "  api/weather/stats:\n",
        "    get:\n",
        "      summary: Retrieve weather statistics\n",
        "      description: Returns weather statistics filtered by date and station ID\n",
        "      parameters:\n",
        "        - in: query\n",
        "          name: station_id\n",
        "          schema:\n",
        "            type: integer\n",
        "          description: ID of the weather station\n",
        "        - in: query\n",
        "          name: page\n",
        "          schema:\n",
        "            type: integer\n",
        "            default: 1\n",
        "          description: Page number for pagination  \n",
        "        - in: query\n",
        "          name: \n",
        "          schema:\n",
        "            type: \n",
        "            default: \n",
        "          description: Returns all results with default pagenumber applicable  \n",
        "      responses:\n",
        "        '200':\n",
        "          description: Successful operation\n",
        "          content:\n",
        "            application/json:\n",
        "              schema:\n",
        "                type: array\n",
        "                items:\n",
        "                  type: object\n",
        "                  properties:\n",
        "                    year:\n",
        "                      type: integer\n",
        "                      description: Year of the weather data\n",
        "                    station_id:\n",
        "                      type: integer\n",
        "                      description: ID of the weather station\n",
        "                    average_maximum_temperature:\n",
        "                      type: number\n",
        "                      format: real\n",
        "                      description: Average maximum temperature (in degrees Celsius)\n",
        "                    average_minimum_temperature:\n",
        "                      type: number\n",
        "                      format: real\n",
        "                      description: Average minimum temperature (in degrees Celsius)\n",
        "                    total_precipitation:\n",
        "                      type: number\n",
        "                      format: real\n",
        "                      description: Total Precipitation (in centimeters)\n",
        "        '400':\n",
        "          description: Invalid request"
      ],
      "metadata": {
        "id": "FUvB3FE98qhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra credits"
      ],
      "metadata": {
        "id": "6Vom4Qtn8FeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To deploy the Weather Data API on Amazon Web Services, I would use the following tools and services from Amazon:\n",
        "\n",
        "1. EC2 (Elastic Compute Cloud): I would use it to launch virtual servers to host the API and the database. I would also use EC2 instances to run the scheduled version of the data ingestion code.\n",
        "2. RDS (Relational Database Service): I would use it to create and manage the SQLite database used by the API. I might migrate to PostgreSQL as well.\n",
        "3. API Gateway:  I would use it to create and deploy the API endpoints that allow users to interact with the weather data.\n",
        "4. Lambda: This is a serverless compute service that runs your code in response to events and automatically, that would allow me to run the scheduled version of the data ingestion code.\n",
        "5. CloudWatch: This is a monitoring service that provides visibility into your cloud resources and applications. I would use it to monitor the API, the database, and the scheduled ingestion code.\n",
        "\n",
        "With these tools and services, I would be able to create an AWS infrastructure that will include an EC2 instance for hosting the API, an RDS instance for the database, and an EC2 instance for running the scheduled ingestion code. I would eventually use CloudFormation tfor automating the deployment of these resources.\n",
        "\n",
        "After finalizing on the infrastructure, I would then create the API endpoints using API Gateway, and connect them to the SQLite database. I would also set up CloudWatch alarms that would help me monitor the API, database, and ingestion code, and later I will configure Lambda to run the data ingestion code on a schedule.\n",
        "\n",
        "With this setup, users to my API would be able to interact with the weather data, and new weather data would be automatically ingested into the database on a regular basis without duplicates."
      ],
      "metadata": {
        "id": "uiIrDkhV8HNu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UDQ8eLle8Gxq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}